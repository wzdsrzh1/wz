# 互信息(MI)损失在训练集和验证集上差异大的原因分析

## 问题描述
- 训练集上 MI ≈ -0.6
- 验证集上 MI ≈ -18
- 差异约30倍

## 可能原因分析

### 1. **随机采样导致的不确定性** ⚠️ **最关键的问题**

在 `loss.py` 的 `mutual_information` 方法中（第242行）：
```python
indices = torch.randperm(img1_flat.shape[0])[:sample_size]
```

**问题**：
- 每次调用都使用 `torch.randperm` 随机采样10000个像素点
- 训练时和验证时采样的像素点完全不同
- 如果验证集图像与训练集图像分布差异大，采样结果会差异更大
- **这是导致数值不稳定的主要原因**

**影响**：
- 同一张图像，不同次计算会得到不同的MI值
- 训练时和验证时的随机性叠加，导致差异被放大

### 2. **数据分布/归一化差异**

**可能的情况**：
- 训练集和验证集的数据分布不同
- 图像数值范围不同（比如训练集在[0,1]，验证集在[0,255]）
- 归一化方式不同或归一化参数不同

**影响**：
- `sigma=0.4` 是固定的高斯核参数
- 如果数据范围差异大，同一个sigma对不同范围的数据效果完全不同
- 例如：数据在[0,1]范围时，sigma=0.4相对较大；数据在[0,255]范围时，sigma=0.4相对很小

### 3. **数值稳定性问题**

在PDF计算中：
```python
kernel_values = torch.exp(-0.5 * (residuals / self.sigma).pow(2))
```

**问题**：
- 如果 `residuals / sigma` 很大，`exp` 值会非常小，接近0
- 如果数据范围不匹配，可能导致大部分kernel_values接近0
- 归一化时分母可能非常小，导致数值不稳定

### 4. **批次处理差异**

- 训练时可能使用 `drop_last=True`，某些批次被丢弃
- 验证时处理所有数据
- 如果批次间数据分布差异大，会导致统计结果不同

### 5. **模型状态差异**

虽然MI损失不直接依赖BatchNorm等，但：
- 训练时模型在 `train()` 模式
- 验证时模型在 `eval()` 模式
- 某些操作（如dropout）的行为不同，可能间接影响融合结果

## 解决方案

### 方案1：固定随机种子（临时解决方案）
在验证时固定随机种子，确保每次计算结果一致。

### 方案2：自适应sigma（推荐）
根据数据范围自动调整sigma值，而不是使用固定值。

### 方案3：使用全部像素点（最稳定）
不使用随机采样，使用全部像素点计算MI（计算量大但稳定）。

### 方案4：改进MI计算方式
使用更稳定的MI计算方法，如基于直方图的方法。

### 方案5：数据预处理一致性
确保训练集和验证集使用相同的归一化方式和参数。
